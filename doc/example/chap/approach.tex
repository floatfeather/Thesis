\chapter{设计}

\section{结合基于频谱的缺陷定位和基于状态覆盖的缺陷定位}
\label{sec:approach_comb}

既然基于频谱的缺陷定位和基于状态覆盖的缺陷定位各有优劣，
那么是否可以结合这两种缺陷定位的方法呢？
事实上已经有研究\parencite{Le2016A,Xuan2014Learning}，结合了多种缺陷定位方法，并且获得了比较好的结果。
但是这些研究的结合方式都是在比较高的层次，
比如使用机器学习方法对不同缺陷定位得到的结果进行组合。
这样的结合方式会有两个缺点。
一是他们没有解释为什么他们的方法会起作用。
二是他们没有深入理解缺陷定位方法起作用的原因，仅仅是把各个方法的结果合在一起。

所以，本文试图提出一个能够结合现有缺陷定位（比如基于频谱的缺陷定位和基于状态覆盖的缺陷定位）的方法去改进缺陷定位技术，
同时本文试图解释这个结合为什么起作用的原因。

虽然在直觉上我们认为基于频谱的缺陷定位和基于状态覆盖的缺陷定位是完全不一样的。
因为基于频谱的缺陷定位依靠的是程序元素的覆盖情况，
而基于状态覆盖的缺陷定位依靠的是用谓词来划分状态。
但是事实上这两种缺陷定位技术有相似的地方，
它们都是通过一个公式对程序元素打分。
基于频谱的缺陷定位的频谱信息，其实相当于是对每一个语句都关联了一个\mycode{true}这样的谓词。
这样看来基于频谱的缺陷定位相当于基于状态覆盖的缺陷定位的一个特殊情况。
而基于状态覆盖的缺陷定位收集的谓词的覆盖信息也可以看做是程序频谱信息的一种，
所以基于状态覆盖的缺陷定位也可以看做基于频谱的缺陷定位的一个特殊情况。

考虑\ref{sec:state_based}章中基于状态覆盖的缺陷定位的例子。
统计性调试和SOBER都无法给出很好的定位结果。
但是当观察统计性调试的覆盖情况\ref{math_2_return}，
我们却可以“猜测”出当前语句很可能是错误语句。
这是因为我们带入了基于频谱的缺陷定位的假设：被失败的测试用例执行的语句，
更有可能有错误。而被通过的测试用例执行的语句，更有可能是正确的。
根据这个假设，表\ref{math_2_return}中的谓词3、4、6都不太可能是能够划分出缺陷状态的谓词，因为它们都没有被失败的测试用例覆盖过。
谓词1最有可能是能够划分出缺陷状态的谓词，其次是谓词2，最后是谓词5。
这是因为谓词1、2、5都被一个失败的测试用例覆盖过，而谓词1没有被通过的测试用例覆盖过。
这种情况下被越少的通过的测试用例覆盖，越有可能就是能够划分出缺陷状态的谓词。
怎样去具体地表示这个怀疑度呢？
这其实是基于频谱的缺陷定位解决的问题了，那就是使用怀疑度公式。
使用Ochiai怀疑度公式去计算表\ref{math_2_return}中谓词的怀疑度，得到表\ref{math_2_ochiai}。
可见谓词1以1.0000的分数远远高于其他谓词，成为怀疑度很大的谓词。
对于每个语句的多个谓词，采用怀疑度最高的谓词的分数作为这个语句的怀疑度。
使用Ochiai怀疑度公式，计算Math的第二个缺陷的各个谓词怀疑度，
缺陷语句排名第3（第1到4名并列），相比于基于频谱的状态覆盖第11位、统计性调试全部为0和SOBER第10的结果，有显著提升。

不仅如此，这样得到的结合了基于频谱的缺陷定位和基于状态覆盖的缺陷定位的结果，
还可以和原始的基于频谱的缺陷定位的结果相结合。
比如Math的第二个缺陷的错误语句，其基于频谱的缺陷定位的怀疑度为0.3780，
加上结合后的谓词怀疑度1.0000，总怀疑度为1.3780，在怀疑度列表中排名第2。
效果好于原始的定位结果和结合后的结果。

基于频谱的缺陷定位和基于状态覆盖的缺陷定位的方法都可以表述为，
给定一个程序元素$e$，一个产生谓词的函数$s$，和一个怀疑度计算公式$r$，
对于这个程序元素$e$，它的分数函数$c$可以表述为：
$$
c(s,e,r) = max_{p \in s(e)}r(p)
$$
对于这个程序元素$e$，首先通过$s(e)$获取其所有谓词。
对于基于频谱的缺陷定位方法这个谓词恒为\mycode{true}。
然后对每个谓词$p$计算其在怀疑度公式$r$下的怀疑度$r(p)$。
这个怀疑度公式包括基于频谱的缺陷定位和基于状态覆盖的缺陷定位怀疑度公式。
上述例子提出的结合的方法，使用的基于频谱的缺陷定位的$r$，和基于状态覆盖的缺陷定位的$s$。
这样可能会得到多个怀疑度，采用某种方式把它们结合起来（这里使用的最基本的$max$函数作为结合怀疑度的方法），
就可以得到这个程序元素的最终分数。

本文提出两种结合方法进行实验：
\begin{itemize}
\item \textbf{\textsc{MaxPred}} \\
对于一个程序元素$e$，在某个怀疑度公式$r$和谓词$s(e)$下，
计算得到的多个怀疑度分数，并取其最大值作为$e$的怀疑度。
\item \textbf{\textsc{LinPred}} \\
给定两组谓词$s_0(e)$和$s_1(e)$，使用\textsc{MaxPred}计算得到
$e$的两个怀疑度$c_0$和$c_1$。
再利用一个线性模型结合两个怀疑度，得到$C(e) = (1 - \alpha) \times c_0 + \alpha \times c_1$。
\end{itemize}

% \begin{itemize}
% \item \textbf{\textsc{MaxPRED}}：
% 给定一个程序元素$e$和一组和$e$相关的谓词$P$，
% 则谓词$e$的怀疑度值是
% 使用基于频谱的缺陷定位公式去计算语句的怀疑度（原始的基于频谱的缺陷定位方法）得到$s_0$，
% 然后和 \textsc{PredSBFL} 计算得到的同一条语句的怀疑度$s_1$取最大值得到新的怀疑度，
% $s = max(s_0, s_1)$
% \item \textbf{\textsc{CombSD}}：
% 使用一个线性模型去结合$s_0$和$s_1$的值，得到新的怀疑度：
% $s = (1 - \alpha) \times s_{0} + \alpha \times s_{1}$。
% \end{itemize}

\begin{table}
\centering
\begin{tabular}{|c|l|c|}
\hline
 & 谓词 & Ochiai分数\\
\hline
1 & \mycode{retValue < 0} &  1.0000 \\
\hline
2 & \mycode{retValue <= 0} &  0.7071 \\
\hline
3 & \mycode{retValue > 0} & 0.0000 \\
\hline
4 & \mycode{retValue >= 0} & 0.0000 \\
\hline
5 & \mycode{retValue != 0} & 0.4082 \\
\hline
6 & \mycode{retValue == 0} & 0.0000 \\
\hline
\end{tabular}
\caption{使用Ochiai计算谓词怀疑度，其中 \\ \mycode{retValue = (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize()}}
\label{math_2_ochiai}
\end{table}

\section{预定义谓词和预测谓词}

在统计性调试和SOBER中，都使用的是预定义的谓词。
一个谓词的好坏决定了能否划分出缺陷状态。

考虑Defects4j中Math的第四个缺陷，其代码如下：
\lstset{language=Java}
\begin{lstlisting}
public Vector3D intersection(final SubLine subLine, final boolean includeEndPoints) {
    // compute the intersection on infinite line 
    Vector3D v1D = line.intersection(subLine.line);
+   if (v1D == null) {
+       return null;
+   } 

    // check location of point with respect to first sub-line
    Location loc1 = remainingRegion.checkPoint(line.toSubSpace(v1D));
    ... 
}
\end{lstlisting}

第4，5，6行是修复缺陷的代码。这个缺陷是缺少了对变量\mycode{v1D}是否是空的判断。
考虑谓词\mycode{v1D == null}，会发现通过的测试用例都不会覆盖这个谓词，只有失败的测试用例覆盖这个谓词。
因为一旦这个谓词为真，那么后续某些使用这个\mycode{v1D}变量的操作就会造成空指针的错误。

然而这个谓词并不能由预定义的谓词得到。
但是事实上代码中其他的地方存在\mycode{var == null}这样的判断。
于是本文提出了一种基于机器学习的预测谓词的方法，来更准确地找出划分缺陷状态的谓词。

或许我们不使用机器学习方法，而是把\mycode{var == null}这样经典的判断加入预定义谓词呢？
但问题是这样的谓词永远是加不完的。
而且对于每个程序，它们可能还拥有跟自己上下文有关的独特的谓词。
所以从它们自己的代码中来学习出谓词是更有效的方法。

\section{缺陷定位框架}
\label{sec:fl_frame}

本文提出了结合了基于频谱的缺陷定位和基于状态覆盖的缺陷定位的缺陷定位方法，
同时还提出了一种机器学习方法去预测谓词。

本文的缺陷定位框架主要包括以下几步
\begin{itemize}
\item \textbf{收集特征} 
当使用预定义谓词时不需要这一步。
假如缺陷代码是版本$v$，则从版本$v$的源代码中提取特征。
特征分为两种，一种是变量预测模型的特征，一种是谓词预测模型的特征。
\item \textbf{训练模型}
当使用预定义谓词时不需要这一步。
把得到的特征放入机器学习模型中训练。
两种特征分别单独训练，得到一个预测变量出现在谓词中概率的模型（简称VAR模型），和一个根据一个变量预测可能出现哪些谓词的模型（简称EXPR模型）。
\item \textbf{收集失败测试用例覆盖的语句}
只有被失败的测试用例覆盖的语句才有可能是错误的语句。
因为只需要对失败测试用例覆盖的语句收集其谓词的覆盖情况就可以了。
\item \textbf{获取谓词}
如果使用预定义谓词，则根据预定义谓词的规则分析代码，得到谓词。
如果使用预测谓词模型，则提取需要插入谓词的相关变量和语句的特征，
放入已经训练好的模型中，预测出当前位置最有可能出现的$N$个谓词。
\item \textbf{收集谓词覆盖情况}
把谓词插入代码中，并执行测试用例，收集谓词的覆盖情况。
不同怀疑度公式收集的覆盖情况可能会有不同。
覆盖情况包括：谓词的真（或假）分支被多少个失败（或通过）的测试用例覆盖，
谓词（无论是真分支还是假分支）被多少个失败（或通过）的测试用例覆盖，
谓词的真（或假）分支在一个失败（或通过）的测试用例中被覆盖的次数等等。
\item \textbf{计算怀疑度}
根据上一步收集的谓词覆盖情况，带入基于频谱的缺陷定位和基于状态覆盖的缺陷定位的怀疑度公式计算怀疑度。
收集语句的覆盖情况，带入怀疑度公式计算怀疑度，并且与谓词怀疑度结合。
\end{itemize}

\section{基于机器学习的预测谓词模型}

对谓词的预测分为三步：
\begin{itemize}
\item 第一步，使用VAR模型预测语句中的某个变量出现在谓词中的概率$P_{var}$。
\item 第二步，使用EXPR模型预测语句中的某个变量会出现在谓词 $pred_i$ 中的概率 $P_{pred_i}$ 。
\item 第三步，将谓词按照$P_{var} \times P_{pred_i}$排序。
\end{itemize}

第一步中的变量是赋值表达式的左值。也就是说我们只会对失败的测试用例覆盖的赋值语句进行表达式的预测。

\subsection{机器学习特征}

对于一个有缺陷的代码，我们从当前这个版本的所有源代码中提取特征。

使用的变量特征和谓词特征如表\ref{var_feature}。
不同的是VAR模型的标签是这个变量是否出现在条件中，
EXPR模型的标签是这个变量相关的谓词是什么。
也就是说VAR模型使用的样本来自于所有变量，而EXPR模型使用的样本仅来自于出现在谓词中的变量。

这些特征有的是认为这些特征相似度更高的变量更可能会有相似的属性。
相似的文件名、函数名可能是实现着相似的功能，比如可能是继承了同一个父类的子类。
变量名相似也可能是有相似的功能，比如 \mycode{len} 和 \mycode{length}。
类型相同同理，比如对一个 \mycode{Object} 类型的变量进行是否为空指针的判断。
相似的功能可能就会使用相似的谓词。
还有特征是描述这个变量的上下文信息，这些特征也会影响谓词。
比如 LastAssign 说明了这个变量值是如何得到的，比如从\mycode{getMin()}函数得到的值\mycode{v}容易出现在谓词中，并且谓词
很可能是\mycode{v < 0}这样的比较。
有的特征直接描述这个变量在条件表达式中的情况，比如 InFor， InCondNum等。


\begin{table}
\centering
\begin{tabular}{|l|l|}
\hline
特征名称 & 特征说明 \\
\hline
FileName & 文件名 \\
\hline
MethodName & 函数名 \\
\hline
VarName & 变量名 \\
\hline
VarType & 变量类型 \\
\hline
LastAssign & 变量最后一次赋值的操作 \\
\hline
Dis0 & 变量声明和使用之间的距离 \\
\hline
PreAssNum & 变量此前赋值的次数 \\
\hline
IsParam & 变量是否是方法的参数 \\
\hline
InFor & 变量是否出现在循环中 \\
\hline
InCondNum & 变量在条件中出现的次数 \\
\hline
BodyUse & 变量在条件语句的语句体里的使用情况 \\
\hline
OutUse & 变量在条件外的使用方式 \\
\hline
\end{tabular}
\caption{VAR模型和EXPR模型特征}
\label{var_feature}
\end{table}

\subsection{机器学习特征编码}

\subsubsection{编码}

对于数值型的变量，直接使用其值作为特征。
而对于分类变量（categorical variable），虽然其值可能表现为0、1、2……
这样的数字，但是其实并不存在$0 < 1 < 2$这样的大小关系。
直接使用其值会让模型以为这个变量存在大小关系。
所以对于分类变量，本文采取独热（one-hot）编码。
比如对于一个值为0、1、2的分类变量$v$，使用新的变量$v_0$、$v_1$、$v_2$代替$v$。
其中$v_i = 1$表示$v = i$，而$v_i = 0$表示$v \ne i$。

\subsubsection{字符串特征编码}

对于字符串类型的特征，比如文件名、函数名和变量名，本文也会使用独热编码。
但是直接使用独热编码会有两个问题：
\begin{enumerate}
\item 特征维度过大。比如对Defects4j中Math项目的第一个缺陷来说，仅不同的方法就有795个。
这意味着如果把方法改成独热编码，将会把一个1维的特征变成795维的特征。
这样可能造成维度灾难\parencite{Richard1957Dynamic}。
虽然一开始随着特征数的上升，机器学习模型的预测效果也会上升，但是当维度过高的时候，实际性能是下降的。
但这还不是最关键的因素。
\item 丢失了字符串内部的特征。
字符串的变量和其它的变量不同，它们之间还有内部的特征。
比如变量名len和length之间的相似度比len和domain之间的相似度要高，
文件名SubLine.java和Line.java之间的相似度比SubLine.java和BracketFinder.java之间的相似度高。
简单地把不同字符串看成完全独立地不同特征会丢失很多有用的信息。
\end{enumerate}

对字符串的编码采取三步。

首先是将字符串转换为向量。对变量名，采取一种类似2-gram的方法。
每一个变量名都会被转成一个长度为$729 (27 \times 27)$的一维向量。
变量名中的大写字母会先被转为小写字符。
对转换后的变量名$s_1s_2...s_n$，考虑每两个相邻字符的字符串$s_1s_2$，$s_2s_3$……$s_{n - 1}s_n$。
这个向量的第i位为1表示变量名中存在两个相邻字符$s_js_{j+1}$，满足$f(s_j) \times 27 + f(s_{j + 1}) = i$。
$f$是一个映射函数，将一个字符转换成一个0到26之间的数字。
对于$f$有$f('a') = 0, f('b') = 1, ..., f('z') = 25$，然后a到z以外的字符都被转为26。
这样的话len和length的特征向量之间就会有两位相同，而len和domain之间则完全没有相同的。
对函数名和文件名，去掉后缀，然后利用Java中使用的驼峰命名法将它们按照驼峰分割开来。
比如 SubLine.java 会被拆为 Sub 和 Line，而 Line.java 得到 Line，BracketFinder.java 得到Bracket和Finder。
收集所有分割后的词（函数名和文件名分开收集），假设有$N_{func}$和$N_{file}$个，
则每个函数名（或文件名）就转成一个长度为$N_{func}$（或$N_{file}$）的向量。
这个向量的第i位为1表示函数名（或文件名）中含有字符串$g_{func}(i)$（$g_{file}(i)$）。
$g_{func}$和$g_{file}$是向量下标和字符串的映射。
比如 $g_{file}(57) = "Line"$ 的话，Line.java的向量的第57位为1，其他位为0。

然后是对字符串转换后的向量进行聚类。
聚类使用的是K-means聚类算法。
因为不同的项目所涉及的变量名、函数名、文件名数量差别较大，不适合使用单一的某个常数作为聚类的类别数。
所以聚类的类别数为$Unique(names) / c$。
其中$names$表示所有变量名或函数名或文件名，$Unique(x)$表示$x$中不重复的值的数量，$c$是某个常数。

最后是根据聚类给字符串编码。
假如聚类结果有$N$个类，那么就把这$N$个类编号为$1$到$N$。
每个类中的每个字符串的编号等于它所处的类的编号。
每个字符串的编号就是它的特征值，对这个特征值使用独热编码就得到最终的特征。
于是通过重新编码和聚类，字符串特征的内部特征被抽取出来，并且字符串特征的维度也被大幅减小。

\subsubsection{预测时的特征新值}

在预测的时候，特征里面可能会有在训练的特征里面没有出现过的值。
如果这个值是数值型的值，那么直接使用这个值就可以。
但是如果是经过编码之后的值，就需要给这个新值一个编码。

为了给出一个和训练时编码一致的编码，需要保存训练时的部分数据。
包括变量名、文件名、函数名的聚类模型，文件名、函数名中向量下标和字符串的对应函数$g_{func}$、$g_{file}$，
训练时使用的独热编码。

对于新的变量名，按照训练时的处理方法将其转为$729 (27 \times 27)$的一维向量。
然后计算出这个向量与训练时变量名聚类模型中的哪个中心点距离更短，把这个变量名划入这个中心点的分类。
最后使用训练时变量名的独热编码给这个分类编码即可。

对于新的文件名或函数名，有两种情况。
第一种情况是，这个文件名虽然没有出现过，但是它按照驼峰拆分之后的字符串都出现过。
这种情况下使用$g_{func}$和$g_{file}$直接构造特征向量。
第二种情况是，这个文件名按照驼峰拆分之后的字符串有没有出现过的。
没有出现过的字符串则会被忽略。
构造出的特征向量使用训练时的聚类模型划分分类，最后使用训练时的独热编码给改分类编码。

对于除变量名、文件名、函数名以外的分类变量，
如果出现了新的值，假设这个分类变量的类别有$C$个，
那么新值转成独热编码后其特征向量为$C$个0。

\subsection{机器学习模型}

本文在小量数据上尝试了多种机器学习模型，最后选定了两种机器学习模型：全连接神经网络和随机森林模型。

\subsubsection{神经网络模型}

VAR模型和EXPR模型使用同样的全连接神经网络。
这个神经网络由一个输入层，六个隐藏层，一个输出层，一个softmax层构成。
输入层的神经元数量和特征数量一致，输出层的神经元数量和分类数量一致。
对于VAR模型来说输出层的神经元有两个，对于EXPR模型来说输出层的神经元数量和可能的谓词数量一样。
六个隐藏层每层都是64个节点。这个是小部分实验之后得出的比较适合的值。
采用的激励函数是广泛使用的线性整流函数（ReLU）。
$$
\mathrm{ReLU}(features) = max(features, 0)
$$
神经网络使用误差逆传播算法进行训练，优化算法使用 Proximal Adagrad 算法。
Proximal Adagrad 算法能够在训练中自动对学习率进行调整，并且能够通过正则化防止过拟合。
损失计算采用的softmax cross entropy。

假如分类数是$c$，softmax层的输入是一个$c \times 1$的向量，输出也是一个$c \times 1$的向量，
表示当前输入的标签是各个类别的概率。
记原始的输入向量是$(a_1, a_2, ..., a_c)$，softmax层的输出是
$(S_1, S_2, ..., S_c)$，则有
$$
S_j = \frac{e^{a_j}}{\sum_{k=1}^c{e^{a_k}}}
$$
以softmax层的输出计算softmax cross enptropy：
$$
E = -\sum_{j = 1}^{c}{y_jlog(S_j)}
$$
其中$y_j$是输入对应的真实的标签。

为避免过拟合，本文采用了早停（early stop）的方法。
训练时会把训练数据分为训练集和验证集。
使用训练集进行训练，然后不断评估当前模型的训练集的损失和验证集的损失。
当训练集的损失不断下降，但是验证集的损失却开始上升时，
说明模型出现了过拟合，停止训练。
然后把训练过程中验证集损失最小时的模型作为最终模型。

\subsubsection{随机森林模型}

随机森林是一种常用的机器学习方法。顾名思义，随机森林是一棵树，包含一个根节点、若干个内部节点和叶节点。
每个叶节点对应一个决策结果，内部节点和根节点则对应于一个属性测试。
根据节点的属性测试，样本被划分到对应的子节点中。
其学习流程的基本思想是分治法。

随机森林中需要依靠节点的纯度来选择最优划分属性。
本文使用的基尼指数来选择划分属性。
假设当前样本集合为$D$，其中第$k$类样本所占比例为$p_k,(k=1,2,...,|\gamma|)$，
则基尼指数为：
$$
\mathrm{Gini}(D) = \sum_{k=1}^{|\gamma|}{\sum_{k^\prime \ne k}{p_kp_{k^\prime}}} = 1 - \sum_{k = 1}^{|\gamma|}p_k^2
$$
基尼指数反映了从数据集中随机选取两个样本，其类别标记不一致的概率。
所以基尼值越小，纯度越高。
所以选择使得划分后基尼指数最小的属性作为最优划分属性。

树的深度没有限制，也就是说节点会被一直展开直到所有叶节点都是纯净的节点（即所包含的样本都只属于同一个分类）或叶节点的样本数量小于2。

\section{收集频谱信息}

代码插装是一种常用的记录程序执行情况、修改程序的方法。
采用的工具是 eclipse 提供的Java Development Tool\footnote{\url{http://www.eclipse.org/jdt/}}，简称JDT。
JDT不仅可以构造给定Java代码的抽象语法树，还可以新建、修改、插入、删除抽象语法树从而新建、修改、插入、删除Java代码。
本章中很多实现都依赖于JDT。

本文使用代码插装技术主要目的是收集频谱信息。
比如为了收集失败测试用例覆盖的语句，可以在每个语句后面加上一个打印语句。
这个打印语句会打印出当前的文件名和对应语句的行数。
用失败的测试用例执行这个插装后的程序，就可以得到失败测试用例覆盖的语句。

对于谓词$P$和一个测试用例$T_i$，可能需要收集四种信息：
\begin{enumerate}
\item $P$是否被$T_i$观察过（无论是真还是假）。
\item $T_i$中$P$是否至少一次为真。
\item $T_i$中$P$为真的次数。
\item $T_i$中$P$为假的次数。
\end{enumerate}

对于基于频谱的缺陷定位的公式来说，需要第2个信息。
对于统计性调试的公式来说，需要第1、2个信息。
对于SOBER的公式来说，需要第3、4个信息。
所以整体来说谓词的插装有两种形式。
第一种用于基于频谱的缺陷定位公式和统计性调试公式：
\lstset{language=Java}
\begin{lstlisting}
// predicateSignature is a string that uniquely represents the predicate.
SpecLogger.observe(predicateSignature);
if (predicate) {
    SpecLogger.cover(predicateSignature);
}
\end{lstlisting}
\mycode{SpecLogger.observe}记录这个谓词为观察过（信息1），
\mycode{SpecLogger.cover}记录这个谓词为真过（信息2）。
第二种用于SOBER公式：
\lstset{language=Java}
\begin{lstlisting}
// predicateSignature is a string that uniquely represents the predicate.
if (predicate) {
    SpecLogger.coverTrueBranch(predicateSignature);
} else {
    SpecLogger.coverFalseBranch(predicateSignature);
}
\end{lstlisting}
\mycode{coverTrueBranch}记录这个谓词为真的次数（信息3），
\mycode{coverFalseBranch}记录这个谓词为假的次数（信息4）。

这几个\mycode{SpecLogger}的函数可以是把自己内部的某个布尔型的成员变量置为真或假，
也可以是把自己内部的某个整型的成员变量加一。
这个\mycode{SpecLogger}对象在每个测试用例开始的时候重置（使用静态方法变量），并在测试用例结束的时候以某种格式将自己记录的信息输出到文件。
\lstset{language=Java}
\begin{lstlisting}
private void testSomething() {
    SpecLogger.reset();
    SpecLogger.testStatus = true;

    // test ...
    ...

    SpecLogger.dump();
}
\end{lstlisting}
第三行是根据当前测试用例\mycode{testSomething}是通过的测试用例还是失败的测试用例而插装的。
最后\mycode{SpecLogger.dump}把记录的信息输出到文件。
其他程序从这个输出文件中可以构造出频谱信息。

\section{不改变程序状态地插入谓词}

统计性调试中自定义的谓词和预测出来的谓词可能有副作用。
使用上一章中的插装方法会改变程序的执行状态，所以需要不改变程序状态地插入谓词。

统计性调试中的谓词要么是两个变量构成的二元表达式，要么就是本来就会在程序中执行的条件表达式。
前者不会有副作用，而后者即使有副作用，由于其本来就要在原程序中执行一次，因此只要利用执行的这一次的结果就可以。

预测出来的谓词可能含有有副作用的函数，或者含有赋值语句。
于是对预测出谓词的静态分析，只留下一定无副作用的谓词。
比如除了部分指定函数（如size），含有其他函数的谓词都会被过滤掉。

插入谓词仍然使用JDT。

\subsection{插入预测的谓词}

通过机器学习模型，每个语句可能会关联一组谓词。
这些谓词会被机器学习模型赋予出现的概率。
最终每个语句我们选择概率最高的5个谓词作为需要插入的谓词。

在插入预测的谓词之前，要先对谓词进行过滤。
过滤包括两步：
\begin{enumerate}
\item 静态分析过滤掉可能不合法的谓词（比如对一个\mycode{int}类型的变量进行下标访问）。
\item 静态分析过滤掉可能有副作用的谓词。
\item 过滤掉不能编译的谓词。
\end{enumerate}

一个预测出来的谓词分为两部分，一个是谓词$P(x)$，一个是变量$v$，最终构成谓词$P(v)$。
一个谓词会被判定为不合法如果它满足以下至少一点：
\begin{itemize}
\item 含有数组访问\mycode{v[i]}且\mycode{v}并不是数组类型。
\item 含有变量访问\mycode{v.a}且\mycode{v}是一个基本数据类型（比如\mycode{int}）的变量。
\item 含有变量访问\mycode{a.v}且\mycode{v}不是\mycode{a}的一个域。
\item \todo{simple name}
\item 含有函数调用\mycode{v.a()}且\mycode{v}是一个基本数据类型变量。
\item 含有函数调用\mycode{f()}且\mycode{f}不属于预定义的合法函数（如\mycode{size}，\mycode{length}，\mycode{toString}，\mycode{contains}，\mycode{containsKey}，\mycode{Math.abs}，\mycode{Double.isInfinite}，\mycode{Double.isNaN}）。
\item 含有域访问\mycode{v.a}且\mycode{v}是一个基本数据类型的变量。
\item 含有中缀表达式\mycode{a op b}且\mycode{a,b}的类型和运算符\mycode{op}不匹配（比如对非数字类型进行加法）。
\end{itemize}

过滤有副作用的谓词主要是过滤掉以下几种：
\begin{itemize}
\item 含有前缀表达式，且其中运算符为\mycode{++}或\mycode{--}。
\item 含有后缀表达式。
\item 含有赋值语句。
\end{itemize}

最后单独地插入每一条谓词，过滤掉不能顺利编译的。
在没有判定谓词是否合法的时候，也可以通过编译来排除不合法的谓词。
但是由于谓词数量较多，通过预处理去掉部分肯定不对的谓词可以加速整个流程。

最后对于一个语句$s$，我们可以得到一组合法无副作用的谓词${P_1,P_2...}$。
我们再加入取反的谓词${!P_1, !P_2, ...}$。

然后就是将收集谓词频谱信息的代码插入到语句前或后。
语句前后都插入的有\mycode{while，for，do}，
插入在语句后面的有赋值语句，
插入在语句前的有\mycode{if，switch}等其他所有语句。

%\mycode{Assignment，VariableDeclarationStatement, ConstructorInvocation, SuperConstructorInvocation}，

\subsection{插入预定义的谓词}

预定义的谓词也可能有副作用，比如赋值语句\mycode{a[b++] = c}的谓词\mycode{a[b++] > d}，
如果使用此前的插装方法，则插入\mycode{if (a[b++] > d)}这样的语句会产生副作用。
但是如果使用中间变量，则上述代码可以重写为：
\lstset{language=Java}
\begin{lstlisting}
temp = c;
a[b++] = temp;
if (temp > d) {
    ...
}
\end{lstlisting}
所以预定义谓词的三种情况，分支、返回、数值对，都可以使用中间变量这样的方式来插入谓词，从而避免了副作用的情况。

由于分支对应多种情况，使用中间变量会比较复杂。
分支的谓词是分支中含有的条件表达式。
\mycode{DoStatement}中的条件表达式的值每次循环都会更新，再考虑上\mycode{continue}这样的语句，
会让条件表达式的更新逻辑非常复杂。
为了简单地插入谓词，并且由于条件表达式的类型都是布尔型，使用一个函数\mycode{logConditionCoverage}替换条件表达式。
原代码为：
\lstset{language=Java}
\begin{lstlisting}
// example.java:
while(!iter.isEmpty()) {
	...
}
\end{lstlisting}
插装了收集谓词频谱信息的语句后，代码被修改为：
\lstset{language=Java}
\begin{lstlisting}
// example.java
while(SpecLogger.logConditionCoverage(!iter.isEmpty(), "!iter.isEmpty()", "!(!iter.isEmpty())") {
	...
}

// SpecLogger.java
public static boolean logConditionCoverage(boolean condition, String trueLogInfo, String falseLogInfo) {
	observe(trueLogInfo);
	observe(falseLogInfo);
	if (condition) {
		cover(trueLogInfo);
	} else {
		cover(falseLogInfo);
	}
	return condition;
}
\end{lstlisting}
这里同时记录了假分支的覆盖情况。这样做有两个目的：
\begin{itemize}
\item 统计性调试中预定义的分支型谓词有条件表达式取反。
\item 和预测谓词加入了谓词取反的情况保持一致。
\end{itemize}

\section{计算怀疑度}

收集频谱信息后，就可以带入计算怀疑度。
无论是机器学习得到的谓词，还是预定义的谓词，都使用表\ref{susp_formula}中的五种公式，以及统计性调试和SOBER总共七种公式进行计算。
通过谓词计算得到的语句$s_i$的怀疑度记为$s_{i1}$。

除了能够使用谓词计算得到怀疑度以外，利用原始的
基于频谱的缺陷定位方法和基于状态覆盖的缺陷定位方法（SOBER除外），还可以计算得到语句的怀疑度$s_{i0}$。
本文尝试结合这两种怀疑度，比如使用$s_i = (1 - \alpha) \times s_{i0} + \alpha \times s_{i1}$作为最终怀疑度。

