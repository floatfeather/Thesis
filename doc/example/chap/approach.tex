\chapter{方法}

\section{现有缺陷定位的不足}

在上一章的分析中我们发现，现有缺陷定位存在不足。

对于基于频谱的缺陷定位来说，它仅仅依赖频谱信息去区分正确语句和错误语句，
会导致很多正确语句也具有很高的怀疑度。
特别地，如果一个正确语句只被失败的测试用例覆盖，那么它将拥有非常高的怀疑度。
这是由于频谱信息的信息量太少，基于频谱的缺陷定位忽略了程序状态等被基于状态覆盖的缺陷定位关注的信息。

而基于状态覆盖的缺陷定位，虽然能够获得比频谱信息更多的信息，
但是现有的方法都依赖于大量的测试用例。
在测试用例不足的时候，基于状态覆盖的缺陷定位无法给出具有区分度的怀疑度。

\section{结合基于频谱的缺陷定位和基于状态覆盖的缺陷定位}

既然基于频谱的缺陷定位和基于状态覆盖的缺陷定位各有优劣，
那么是否可以结合这两种缺陷定位的方法呢？
事实上已经有研究\parencite{Le2016A,Xuan2014Learning}，结合了多种缺陷定位方法，并且获得了比较好的结果。
\todo{展开}。
但是这些研究的结合方式都是在比较高的层次，
比如使用机器学习方法对不同缺陷定位得到的结果进行组合。
这样的结合方式会有两个缺点。
一是他们难以解释为什么他们的方法会起作用。
二是他们没有深入理解缺陷定位方法起作用的原因，仅仅是把各个方法的结果合在一起。

所以，本文试图提出一个能够结合多种缺陷定位（比如基于频谱的缺陷定位和基于状态覆盖的缺陷定位）的方法去改进缺陷定位技术，
同时本文试图解释这个结合为什么起作用的原因。

虽然在直觉上我们认为基于频谱的缺陷定位和基于状态覆盖的缺陷定位是完全不一样的。
因为基于频谱的缺陷定位依靠的是程序元素的覆盖情况，
而基于状态覆盖的缺陷定位依靠的是用谓词来划分状态。
但是事实上这两种缺陷定位技术有相似的地方。
基于频谱的缺陷定位的频谱信息，其实相当于是对每一个语句都关联了一个\mycode{true}这样的谓词。
这样看来基于频谱的缺陷定位相当于基于状态覆盖的缺陷定位的一个特殊情况。
而基于状态覆盖的缺陷定位收集的谓词的覆盖信息也可以看做是程序频谱信息的一种，
所以基于状态覆盖的缺陷定位也可以看做基于频谱的缺陷定位的一个特殊情况。

考虑\ref{sec:state_based}章中基于状态覆盖的缺陷定位的例子。
统计性调试和SOBER都无法给出很好的定位结果。
但是当观察统计性调试的覆盖情况\ref{math_2_return}，
我们却可以“猜测”出当前语句很可能是错误语句。
这是因为我们带入了基于频谱的缺陷定位的假设：被失败的测试用例执行的语句，
更有可能有错误。而被通过的测试用例执行的语句，更有可能是正确的。
根据这个假设，表\ref{math_2_return}中的谓词3、4、6都不太可能是能够划分出缺陷状态的谓词，因为它们都没有被失败的测试用例覆盖过。
谓词1最有可能是能够划分出缺陷状态的谓词，其次是谓词2，最后是谓词5。
这是因为谓词1、2、5都被一个失败的测试用例覆盖过，而谓词1没有被通过的测试用例覆盖过。
这种情况下被越少的通过的测试用例覆盖，越有可能就是能够划分出缺陷状态的谓词。
怎样去具体地表示这个怀疑度呢？
这其实是基于频谱的缺陷定位解决的问题了，那就是使用怀疑度公式。
使用Ochiai怀疑度公式去计算表\ref{math_2_return}中谓词的怀疑度，得到表\ref{math_2_ochiai}。
可见谓词1以1.0000的分数远远高于其他谓词，成为怀疑度很大的谓词。
使用Ochiai怀疑度公式，计算Math的第二个缺陷的各个谓词怀疑度，
错误语句排名第3（第1到4名并列），相比于基于频谱的状态覆盖第11位、统计性调试全部为0和SOBER第10的结果，有显著提升。

\begin{table}
\centering
\begin{tabular}{|c|l|c|}
\hline
 & 谓词 & Ochiai分数\\
\hline
1 & \mycode{retValue < 0} &  1.0000 \\
\hline
2 & \mycode{retValue <= 0} &  0.7071 \\
\hline
3 & \mycode{retValue > 0} & 0.0000 \\
\hline
4 & \mycode{retValue >= 0} & 0.0000 \\
\hline
5 & \mycode{retValue != 0} & 0.4082 \\
\hline
6 & \mycode{retValue == 0} & 0.0000 \\
\hline
\end{tabular}
\caption{使用Ochiai计算谓词怀疑度，其中 \\ \mycode{retValue = (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize()}}
\label{math_2_ochiai}
\end{table}

\section{预测谓词}

在统计性调试和SOBER中，都使用的是预定义的谓词。
一个谓词的好坏决定了能否划分出缺陷状态。

考虑Defects4j中Math的第四个缺陷，其代码如下：
\lstset{language=Java}
\begin{lstlisting}
public Vector3D intersection(final SubLine subLine, final boolean includeEndPoints) {
    // compute the intersection on infinite line 
    Vector3D v1D = line.intersection(subLine.line);
+   if (v1D == null) {
+       return null;
+   } 

    // check location of point with respect to first sub-line
    Location loc1 = remainingRegion.checkPoint(line.toSubSpace(v1D));
    ... 
}
\end{lstlisting}

第4，5，6行是修复缺陷的代码。这个的缺陷是缺少了对变量\mycode{v1D}是否是空的判断。
考虑谓词\mycode{v1D == null}，会发现通过的测试用例都不会覆盖这个谓词，只有失败的测试用例覆盖这个谓词。
因为一旦这个谓词为真，那么后续某些使用这个\mycode{v1D}变量的操作就会造成空指针的错误。

然而这个谓词并不能由预定义的谓词得到。
但是事实上代码中其他的地方存在\mycode{var == null}这样的判断。
于是本文提出了一种基于机器学习的预测谓词的方法，来更准确地找出划分缺陷状态的谓词。

或许我们不使用机器学习方法，而是把\mycode{var == null}这样经典的判断加入预定义谓词呢？
但问题是这样的谓词永远是加不完的。
而且对于每个程序，它们可能还拥有跟自己上下文有关的独特的谓词。
所以从它们自己的代码中来学习出谓词是更有效的方法。

\subsection{机器学习特征}

对于一个有缺陷的代码，我们从当前这个版本的所有源代码中提取特征。\todo{现在提取的特征的说明}

\subsection{机器学习模型}

本文在小量数据上尝试了多种机器学习模型，最后选定了两种机器学习模型：全连接神经网络和决策树模型。

对谓词的预测分为三步：
\begin{itemize}
\item 第一步，预测语句中的某个变量出现在谓词中的概率$P_{var}$。
\item 第二步，预测语句中的某个变量会出现在谓词$pred_i$中的概率$P_{pred_i}$。
\item 第三步，将谓词按照$P_{var} \times P_{pred_i}$排序。
\end{itemize}

第一步中的变量是赋值表达式的左值。也就是说我们只会对失败的测试用例覆盖的赋值语句进行表达式的预测。

这样就可以得到谓词和它们的重要度。

\subsection{谓词副作用}

和统计性调试中自定义的谓词不同，预测出来的谓词可能有副作用。
统计性调试中的谓词要么是两个变量构成的二元表达式，要么就是本来就会在程序中执行的条件表达式。
前者不会有副作用，而后者即使有副作用，由于其本来就要在原程序中执行一次，因此只要利用执行的这一次的结果就可以。

预测出来的谓词可能含有有副作用的函数，或者含有赋值语句。
于是对预测出谓词的静态分析，只留下一定无副作用的谓词。
比如除了部分指定函数（如size），含有其他函数的谓词都会被过滤掉。

\section{缺陷定位框架}

本文的缺陷定位框架主要包括以下几步
\begin{itemize}
\item \textbf{收集特征} 
当使用预定义谓词时不需要这一步。
假如缺陷代码是版本$v$，则从版本$v$的源代码中提取特征。
特征分为两种，一种是变量预测模型的特征，一种是谓词预测模型的特征。
\item \textbf{训练模型}
当使用预定义谓词时不需要这一步。
把得到的特征放入机器学习模型中训练。
两种特征分别单独训练，得到一个预测变量出现在谓词中概率的模型（简称VAR模型），和一个根据一个变量预测可能出现哪些谓词的模型（简称EXPR模型）。
\item \textbf{收集失败测试用例覆盖的语句}
只有被失败的测试用例覆盖的语句才有可能是错误的语句。
因为只需要对失败测试用例覆盖的语句收集其谓词的覆盖情况就可以了。
\item \textbf{获取谓词}
如果使用预定义谓词，则根据预定义谓词的规则分析代码，得到谓词。
如果使用预测谓词模型，则提取需要插入谓词的相关变量和语句的特征，
放入已经训练好的模型中，预测出当前位置最有可能出现的$N$个谓词。
\item \textbf{收集谓词覆盖情况}
把谓词插入代码中，并执行测试用例，收集谓词的覆盖情况。
不同怀疑度公式收集的覆盖情况可能会有不同。
覆盖情况包括：谓词的真（或假）分支被多少个失败（或通过）的测试用例覆盖，
谓词（无论是真分支还是假分支）被多少个失败（或通过）的测试用例覆盖，
谓词的真（或假）分支在一个失败（或通过）的测试用例中被覆盖的次数等等。
\item \textbf{计算怀疑度}
根据上一步收集的谓词覆盖情况，带入基于频谱的缺陷定位和基于状态覆盖的缺陷定位的怀疑度公式计算怀疑度。
\end{itemize}
