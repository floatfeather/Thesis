\chapter{相关工作}

本章将介绍自动缺陷定位、机器学习的相关工作和缺陷定位所使用的数据集以帮助更好理解本文的工作。

\section{自动缺陷定位相关工作}

程序切片\parencite{Weiser1981Program,Weiser1984Program}是自动调试最早的技术之一，
但是程序切片之后可能出错的语句数量仍然比较庞大。
为了解决程序切片调试方法的短板，一种通过观察错误程序的执行特征和正确程序的执行特征的调试技术被提出。
这些技术通过收集程序执行信息，观察不同的某种特征，来定位缺陷。
比如使用路径概要\parencite{Reps1997The}，反例\parencite{Ball2003From,Groce2004Understanding}，语句覆盖\parencite{Jones2002Visualization}和谓词值\parencite{Liblit2005Scalable,Liu2005SOBER}等等。

本文根据北京大学熊英飞研究员对缺陷定位的分类\parencite{YingfeiFL}，将缺陷定位分为以下几类。

\begin{itemize}
\item 基于切片的缺陷定位
\item 基于频谱的缺陷定位
\item 基于状态覆盖的缺陷定位
\item 基于变异的缺陷定位
\item 基于构造正确执行状态的缺陷定位
\item 基于算法式调试的缺陷定位
\item 基于差异化调试的缺陷定位
\end{itemize}

本文的研究内容主要根据基于频谱的缺陷定位和基于状态覆盖的缺陷定位。

\subsection{基于切片的缺陷定位}

Weiser在1981年提出的程序切片\parencite{Weiser1981Program,Weiser1984Program}是自动调试（特别是缺陷定位）最早的技术之一。
给定一个程序$P$和一个在$P$的语句$s$中使用的变量$v$，程序切片会找到$P$中所有可能会影响$s$中$v$的值的语句。
如果$s$中$v$的值是错误的，那么导致这个错误的缺陷语句一定在这个切片当中。
也就是说，不在这个切片当中的语句可以在调试过程中被忽略。
尽管程序切片已经减少了可能出错的语句的数量，但是切片中的语句的数量仍然比较大。
为了解决这个问题，Korel和Laski在1988年提出了动态程序切片\parencite{Korel1988Dynamic}。
动态程序切片计算某一个特定执行的切片。
后来又有很多的动态程序切片的变种被提出\parencite{Demillo1996Critical,Gyim1999An,Zhang2006Pruning,Zhang2003Precise}，用于解决调试问题，并且产生了大量研究工作\parencite{Agrawal1993Debugging,Liu2007Indexing,Al2005The,Alves2011Fault,Ju2014HSFal,Wotawa2010Fault,Mao2014Slice}。

\subsection{基于频谱的缺陷定位}

基于频谱的缺陷定位是使用最广泛的自动化缺陷定位方法\parencite{YingfeiFL}。
程序频谱（~Program~ Spectrum）最早由Reps等人于1997年提出\parencite{Reps1997The}，用于解决千年虫问题。
Harrold 等人在2002年\parencite{Harrold2000An}提出使用测试覆盖信息作为频谱信息的调试方法。
Renieris等人在 2003年提出使用通过的测试用例和失败的测试用例进行缺陷定位\parencite{Renieres2003Fault}，奠定了此后基于频谱的缺陷定位的基础。

考虑一种极端的情况。
比如当某一个语句$s$被执行的之后，测试用例就会失败。
而通过的测试用例都不会执行语句$s$。
那么语句$s$很有可能就是导致缺陷的语句。
找出所有这样的语句$s$就可以大幅减少需要排查错误的语句。
但是，在实际的代码中这种极端的情况很少出现。
对于一个出错的语句$s$，它很可能既被失败的测试用例执行，也被通过的测试用例执行。
因为一个语句在其不同的上下文作用下会产生不同的效果。
简单地计算通过的测试用例覆盖的语句和失败的测试用例覆盖的语句的差集是无法准确找出错误语句的。
利用通过的测试用例覆盖的语句的交集和并集，与失败的测试用例覆盖的语句取差集，是最早的一种基于频谱的缺陷定位方法\parencite{Renieres2003Fault}。
这种方法也隐含着基于频谱的缺陷定位的假设：被失败的测试用例执行的语句，更有可能有错误。而被通过的测试用例执行的语句，更有可能是正确的。

Jones等人提出的Tarantula\parencite{Jones2002Visualization}，直观地给开发者展示了每个语句在通过的测试用例和失败的测试用例下的参与情况。
参与情况也被称为怀疑度。
% 每条语句的参与情况，使用公式
% $$
% \mathrm{Tarantula}(s) = \frac{\frac{a_{ep}}{a_{p}}}{\frac{a_{ep}}{a_{p}} + \frac{a_{ef}}{a_{f}}}
% $$
% 计算。
% 这个公式计算的值也被称为怀疑度。
怀疑度更高的语句会在怀疑列表更靠前的位置。
相比于交集并集差集的方法，Tarantula在Siemens数据集上可以将错误的语句放在怀疑列表更前面的位置\parencite{Jones2005Empirical}。

Tarantula之后，又有很多计算怀疑度的公式被提出。
效果比较好的Ochiai由Abreu等人提出\parencite{Abreu2006An}。
% $$
% \mathrm{Ochiai}(s) = \frac{a_{ef}}{\sqrt{a_{f} \times (a_{ef} + a_{ep})}}
% $$
Ochiai由\parencite{Meyer2004Comparison}提出用于计算基因的相似度。
Abreu等人将其引入用于计算怀疑度，并与Jaccard\parencite{Chen2002Pinpoint}，Tarantula，AMPLE\parencite{Dallmeier2005Lightweight}比较，发现Ochiai计算的怀疑度使得定位效果更好\parencite{Abreu2006An,Abreu2007On}。
此后Xie等人在理论上证明了不存在单一最佳公式\parencite{Xie2013A}，
对怀疑度公式的研究一直没有停下。

除了直接提出用于计算的公式之外，研究人员也开始使用机器学习的方法去学习怀疑度的公式。
Wong等人提出使用反向传播神经网络来定位缺陷\parencite{W2009BP}。
使用的输入数据是频谱信息（语句覆盖信息）和对应的测试用例是通过还是失败。
输入数据每一行对应一个测试用例。
第i列为1表示的是该测试用例覆盖了第i个语句，为0则表示没有覆盖。
预测的标签为1表示该测试用例失败了，为0表示通过了。
为了减少需要分析的可能出错的语句的个数（每一行输入数据的维度），优先使用所有失败的测试用例覆盖的语句。
此后Wong又提出了使用径向基核函数的神经网络来定位缺陷\parencite{Wong2012Effective}。

\subsection{基于状态覆盖的缺陷定位}

在缺陷定位的时候，定位的程序元素的大小也会影响结果。程序元素可以是一条语句，一个方法，一个文件。
程序元素的粒度越细，对测试信息的利用越精确。
然而单个元素上覆盖的测试数量越少，统计显著性越低。
如果把程序的每个执行状态作为程序元素，那么这会是一个比语句更加精细的粒度。
定位结果也将更加精细，对测试的利用也会更加充分。
但是，几乎不会有两个测试覆盖完全相同的状态，因为一个状态所包含的上下文信息往往十分复杂，很难完全一致。
于是使用抽象状态代替具体状态。
使用谓词将具体状态划分为抽象状态。
谓词是形如\mycode{a $>$ 0}这样的条件表达式。

Liblit等人最早提出了预定义谓词来划分状态\parencite{Liblit2005Scalable}，并提出了统计性调试。
通过预定义在哪些代码结构中插入哪些谓词，统计性调试能够收集到许多抽象状态的覆盖情况。
% 利用表\ref{state_symbol}中的数学符号，统计性调试的公式可以表达为
% $$
% \mathrm{StatisticalDebugging}(s) = \frac{2}{\frac{1}{\frac{t_f}{t_f + t_p} - \frac{a_f}{a_f + a_p}} + \frac{log(F)}{log(t_f)}}
% $$

Liu等人改进了计算公式，提出了SOBER\parencite{Liu2006Statistical}。
虽然Liblit的方法可以有效定位一些错误，但是Liblit的方法只考虑了一个谓词是否在一次执行中为真，
而没有考虑为真的次数。
SOBER提出新的计算公式，从概率分布的角度来计算怀疑度。
% 公式计算的是对一个谓词，在失败的测试用例下这个谓词为真的概率分布，和在通过的测试用例下这个谓词为真的概率分布是否相似。
% 如果概率分布无论是在失败的测试用例中还是通过的测试用例中都一样，那么这个谓词对应的变量等和缺陷的关系就越小。
% 如果两个概率分布相差很大，说明这个谓词对应的抽象状态很有可能就有缺陷状态。
% 引入这个缺陷状态的语句很可能就是出错的语句。

除了预定义谓词以外，研究人员还提出各种从程序中获取谓词的方法。
Le等人提出 Savant\parencite{Le2016A} ，使用程序中的不变式的变化来划分状态。
程序中的不变式使用 Daikon\parencite{Ernst2007The} 挖掘。
Savant使用Learning-to-rank方法，通过分析经典的怀疑度分数和在通过的测试用例和失败的测试用例上观察到的不变式，来定位错误的方法。
Savant基于三个出发点。一，在失败的测试用例和通过的测试用例中表现出不同的不变式的程序元素，被怀疑是有错误的。
二，如果这些程序元素拥有很高的经典的怀疑度分数，那么它们更有可能是错误的。
三，有一些不变式比其他不变式更加可疑，比如\mycode{ x == null}。
% 而 Savant 的工作并没有引用 Liblit \parencite{Liblit2005Scalable}和 Liu \parencite{Liu2006Statistical}，
% 很可能是在不知道统计性调试的情况下完成的。

\subsection{基于变异的缺陷定位}

变异是对程序的任意随机修改，由变异算子得到。
变异分析是测试领域的一个概念，被用于衡量一个测试集的好坏。
变异分析在程序中插入变异，得到很多变异体，然后使用一组测试去执行变异体。
如果一个测试集中任意测试在一个变异体上得到不同的结果，那么这个变异体被这个测试杀死。
能杀死越多变异体的测试集越好。

变异被引入缺陷定位，用于定位缺陷。
Papadakis等人提出Metallaxis\parencite{Papadakis2015Metallaxis}，一个基于变异的缺陷定位。
Metallaxis基于两个假设：
\begin{itemize}
\item 当变异和错误在一个程序的同一条语句上时，失败的测试用例输出发生变化的概率大于通过的测试用例输出发生变化的概率。
\item 当变异和错误不在同一条语句上时，通过测试用例输出发生变化的概率大于失败的测试用例输出发生变化的概率。
\end{itemize}
基于表\ref{mutant_symbol}，Metallaxis的怀疑度计算公式为
$$
\mathrm{Metallaxis}(m) = \frac{m_f}{\sqrt{F \times (m_f + m_p)}}
$$
与Ochiai类似。

Moon等人提出另一个基于变异的缺陷定位技术MUSE\parencite{Moon2014Ask}。
MUSE利用变异分析去捕捉单个语句和观察到的缺陷之间的关系。
MUSE基于的两个假设是：
\begin{itemize}
\item 一个失败的测试用例，比起在变异了正确语句的变异体上，在变异了错误语句的变异体上更容易变成通过的。
\item 一个通过的测试用例，比起在变异了失败语句的变异体上，在变异了正确语句的变异体上更容易变成失败的。
\end{itemize}
基于表\ref{mutant_symbol}，MUSE的怀疑度计算公式为
$$
\mathrm{MUSE}(m) = m_{f2p} - m_{p2f} \times \frac{\sum_{m}^{}{m_{f2p}}}{\sum_{m}^{}{m_{p2f}}}
$$

\begin{table}
\centering
\caption{基于变异的缺陷定位的数学符号及其意义}
\begin{tabular}{|c|c|}
\hline
$m$ & 变异体 \\
\hline
$m_f$ & 变异m导致输出发生变化的失败的测试用例个数 \\
\hline
$m_p$ & 变异m导致输出发生变化的通过的测试用例个数 \\
\hline
$m_{f2p}$ & 变异m导致失败的测试用例变成通过的测试用例的个数 \\
\hline
$m_{p2f}$ & 变异m导致通过的测试用例变成失败的测试用例的个数 \\
\hline
$F$ & 失败的测试用例的个数 \\
\hline
\end{tabular}
\label{mutant_symbol}
\end{table}

\subsection{基于构造正确执行状态的缺陷定位}

MUSE通过变异体，可以把失败的测试用例变成通过，通过的测试用例变成失败的。
假如有一个变异体，它可以把失败的测试用例变成通过的，且不会影响通过的测试用例，那么这个变异体很可能就是缺陷的补丁。
但是直接分析出这样的变异体是很困难的。

Zhang提出的谓词翻转\parencite{Zhang2006Locating}巧妙地避免了直接分析出正确的补丁，而是使用改变程序状态来达到相同的目的。
假如出错的是一个布尔表达式，改变程序中一个布尔表达式的取值（把真变成假，或者把假变成真），强制改变执行的分支。
假如谓词翻转后，失败的测试用例变成通过的，那么对应的布尔表达式很可能有错误。

谓词翻转是局限在布尔表达式，天使调试\parencite{Chandra2011Angelic}则试图解决任意表达式的错误。
天使调试要求同时具有天使性和灵活性。
天使性是指，存在常量c（天使值）把表达式的求值结果替换成c，失败的测试变得通过。
灵活性是指，对于一个修复的候选$e$，和一个通过测试用例输入$I_p$，如果把$e$
的值替换成一个不同的值（不同于$I_p$下$e$的值），这个测试仍然通过。
利用符号执行约束求解计算得到天使值。
也由于符号执行的开销，天使调试无法应用到大型程序上。

\subsection{基于算法式调试的缺陷定位}

Shapiro提出的算法式调试\parencite{Shapiro1982Algorithmic}，通过对子问题询问“是”或“否”来定位缺陷。
算法式调试把复杂的计算步骤拆为小的子问题。
算法式调试的一个问题是，子问题的正确结果可能是不知道的。
如果是让人进行交互式地判断，那么人需要花费时间计算判断子问题的结果。

\subsection{基于差异化调试的缺陷定位}

差异化调试由Zeller等人提出\parencite{Zeller2002Isolating,Zeller2002Simplifying}。
不同于以往的使用动态分析或静态分析的方法去关注源代码，
差异化调试关注程序状态，特别地，差异化调试关注当程序没有出错时的程序状态和程序出错时的程序状态。
差异化调试尝试找到一个最小的修改集合，当把这个集合应用到没有出错时的程序状态后，程序出错了。

\section{机器学习相关工作}

近年来，机器学习相关的工作在高速地发展中。
机器学习也越来越多地被应用到软件工程的领域，并且发挥着重要的作用。
神经网络是一种常用的机器学习模型。
神经网络的定义多种多样，采用 Kohonen 1998年在期刊《Neural Networks》上的定义，为
“神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真是世界物体所作出的交互反应”。
本文使用的误差后向传播网络能够近似复杂的非线性函数\parencite{Hecht1992Theory}。
Neumann等人提出一种结合了主成分分析和误差后向传播网络的软件风险分析\parencite{Neumann2002An}。
Tadayon使用神经网络做软件代价评估。
在缺陷定位方面，也有很多神经网络的应用。
比如之前提到的Wong的两篇工作\parencite{W2009BP,Wong2012Effective}。

\section{缺陷定位的数据集}

要研究缺陷定位，需要一个包含缺陷的数据集。
这个数据集一般来说需要有多个缺陷。
对每一个缺陷，会有对应的测试用例，和对应的一个正确的版本。
这些测试用例中既有通过的，也必定有失败的。
失败的这个测试用例就是由缺陷导致。

Siemens数据集\parencite{Hutchins1994Experiments}是一个很早的数据集，用于测试充分性的实验。
它由七个C程序组成，大小在141行到512行之间。
这七个C程序衍生出132个有缺陷的C程序。
每一个错误版本会恰好有一个缺陷。
这个缺陷可能涉及多行甚至多个文件。
但是这些程序的缺陷是由作者手动插入的，根据作者的描述其实和一个简单的变异操作非常相似。
Siemens数据集的输入被构造用于实现完全的代码覆盖。
尽管它一开始并不是被用于缺陷定位，但是很多缺陷定位技术都使用它来验证效果，比如最早的基于频谱的缺陷定位方法\parencite{Renieres2003Fault}，Ochiai\parencite{Abreu2006An,Abreu2007On}，
SOBER\parencite{Liu2006Statistical}，BPNN\parencite{W2009BP}等等。

Defects4j数据集\parencite{Just2014Defects4J}是一个真实、独立、可重现缺陷的数据集。
它的v1.0版本由五个Java开源项目的357个缺陷组成（该数据集仍在更新当中）。
每一个错误版本会恰好有一个缺陷。
这个缺陷可能涉及多行甚至多个文件。
与Siemens数据集相比，~Defects4j~数据集的缺陷和测试用例都更接近实际开发情况。
Savant\parencite{Le2016A}就是在Defects4j数据集上验证的。
